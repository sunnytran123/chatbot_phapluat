import os
import json
import faiss
import numpy as np
import mysql.connector
from docx import Document
from openai import OpenAI

# ===== C·∫•u h√¨nh =====
client = OpenAI(api_key="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")

duong_dan_word = r"C:\Users\phuon\Desktop\luat\luat_hinhsu.docx"
duong_dan_txt = r"C:\Users\phuon\Desktop\luat\toanvan.txt"
duong_dan_faiss = r"D:\python\chatbot_phapluat\faiss_data\vanban.index"
duong_dan_lich_su_faiss = r"D:\python\chatbot_phapluat\faiss_data\lichsu.index"
duong_dan_lich_su_json = r"D:\python\chatbot_phapluat\faiss_data\lichsu.json"

nguong_trung_khop = 0.85  # 85%

# ===== K·∫øt n·ªëi MySQL =====
conn = mysql.connector.connect(
    host="localhost",
    user="root",
    password="",
    database="chatbot_phapluat"
)
cursor = conn.cursor()

cursor.execute("""
CREATE TABLE IF NOT EXISTS vanban (
    id INT PRIMARY KEY,
    noidung TEXT,
    vector TEXT
)
""")

# ===== H√†m l·∫•y embedding =====
def get_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return response.data[0].embedding

# ===== T·∫°o file TXT t·ª´ Word =====
if not os.path.exists(duong_dan_txt):
    print("‚ö†Ô∏è Ch∆∞a c√≥ file TXT, t·∫°o t·ª´ Word...")
    if not os.path.exists(duong_dan_word):
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file Word t·∫°i {duong_dan_word}")

    doc = Document(duong_dan_word)
    text_full = " ".join(para.text.strip() for para in doc.paragraphs if para.text.strip())

    with open(duong_dan_txt, "w", encoding="utf-8") as f:
        f.write(text_full)
    print("‚úÖ ƒê√£ t·∫°o file TXT.")
else:
    with open(duong_dan_txt, "r", encoding="utf-8") as f:
        text_full = f.read()
    print("‚úÖ ƒê√£ c√≥ file TXT.")

print(f"‚úÖ T·ªïng k√Ω t·ª± trong d·ªØ li·ªáu: {len(text_full)}")

# ===== Load ho·∫∑c kh·ªüi t·∫°o FAISS ch√≠nh =====
os.makedirs(os.path.dirname(duong_dan_faiss), exist_ok=True)
if os.path.exists(duong_dan_faiss):
    index = faiss.read_index(duong_dan_faiss)
    print("‚úÖ ƒê√£ load FAISS d·ªØ li·ªáu ch√≠nh.")
else:
    index = faiss.IndexIDMap(faiss.IndexFlatL2(1536))
    print("‚ö†Ô∏è Ch∆∞a c√≥ FAISS d·ªØ li·ªáu ch√≠nh, t·∫°o m·ªõi.")

# ===== Load ho·∫∑c kh·ªüi t·∫°o FAISS l·ªãch s·ª≠ =====
os.makedirs(os.path.dirname(duong_dan_lich_su_faiss), exist_ok=True)
if os.path.exists(duong_dan_lich_su_faiss):
    index_lichsu = faiss.read_index(duong_dan_lich_su_faiss)
    print("‚úÖ ƒê√£ load FAISS l·ªãch s·ª≠.")
else:
    index_lichsu = faiss.IndexIDMap(faiss.IndexFlatL2(1536))
    print("‚ö†Ô∏è Ch∆∞a c√≥ FAISS l·ªãch s·ª≠, t·∫°o m·ªõi.")

# ===== Load l·ªãch s·ª≠ JSON =====
if os.path.exists(duong_dan_lich_su_json):
    with open(duong_dan_lich_su_json, "r", encoding="utf-8") as f:
        lich_su = json.load(f)
else:
    lich_su = {}

# ===== X·ª≠ l√Ω d·ªØ li·ªáu n·∫øu ch∆∞a c√≥ =====
chunk_size = 2500
chunk_overlap = 300

cursor.execute("SELECT COUNT(*) FROM vanban")
so_dong = cursor.fetchone()[0]

if so_dong == 0 or not os.path.exists(duong_dan_faiss):
    print("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu, b·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
    start = 0
    id_dem = 1

    while start < len(text_full):
        chunk = text_full[start:start + chunk_size]
        if chunk.strip():
            print(f"üîß ƒêo·∫°n {id_dem}: {chunk[:100]}...")
            vector = get_embedding(chunk)
            vector_np = np.array([vector], dtype=np.float32)

            index.add_with_ids(vector_np, np.array([id_dem]))
            vector_str = json.dumps(vector)
            cursor.execute("INSERT INTO vanban (id, noidung, vector) VALUES (%s, %s, %s)", (id_dem, chunk, vector_str))
            conn.commit()

        start += chunk_size - chunk_overlap
        id_dem += 1

    faiss.write_index(index, duong_dan_faiss)
    print("‚úÖ ƒê√£ l∆∞u FAISS d·ªØ li·ªáu ch√≠nh.")

# ===== V√≤ng l·∫∑p h·ªèi ƒë√°p =====
while True:
    cau_hoi = input("\n‚ùì Nh·∫≠p c√¢u h·ªèi (ho·∫∑c 'exit' ƒë·ªÉ tho√°t): ")
    if cau_hoi.lower() == "exit":
        break

    vector_hoi = get_embedding(cau_hoi)
    vector_np = np.array([vector_hoi], dtype=np.float32)

    # ===== Ki·ªÉm tra l·ªãch s·ª≠ tr∆∞·ªõc =====
    if index_lichsu.ntotal > 0:
        D_lichsu, I_lichsu = index_lichsu.search(vector_np, 1)
        khoang_cach = D_lichsu[0][0]
        do_tuong_dong = 1 - (khoang_cach / 2)  # Chu·∫©n h√≥a gi√° tr·ªã

        if do_tuong_dong >= nguong_trung_khop:
            id_ls = int(I_lichsu[0][0])
            cau_tra_loi = lich_su.get(str(id_ls), "")
            print(f"\nüïë ƒê√£ t√¨m th·∫•y c√¢u tr·∫£ l·ªùi t·ª´ l·ªãch s·ª≠ (T∆∞∆°ng ƒë·ªìng {do_tuong_dong*100:.2f}%):\n{cau_tra_loi}\n")
            continue

    # ===== T√¨m d·ªØ li·ªáu ch√≠nh n·∫øu l·ªãch s·ª≠ ch∆∞a c√≥ =====
    k = 5
    D, I = index.search(vector_np, k)

    noi_dung_ghep = ""
    for id_chunk in I[0]:
        if id_chunk == -1:
            continue
        cursor.execute("SELECT noidung FROM vanban WHERE id = %s", (int(id_chunk),))
        row = cursor.fetchone()
        if row:
            noi_dung_ghep += row[0] + "\n"

    if not noi_dung_ghep.strip():
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p.")
        continue

    prompt = f"""
D·ª±a tr√™n c√°c th√¥ng tin sau, h√£y tr·∫£ l·ªùi c√¢u h·ªèi. Ch·ªâ d√πng th√¥ng tin cung c·∫•p, kh√¥ng th√™m d·ªØ li·ªáu ngo√†i:
{noi_dung_ghep}
C√¢u h·ªèi: {cau_hoi}
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini-2024-07-18",
        messages=[{"role": "user", "content": prompt}]
    )
    tra_loi = response.choices[0].message.content
    print(f"\n‚úÖ Tr·ª£ l√Ω tr·∫£ l·ªùi:\n{tra_loi}\n")

    # ===== L∆∞u v√†o l·ªãch s·ª≠ =====
    id_lich_su = index_lichsu.ntotal + 1
    vector_np_ls = np.array([vector_hoi], dtype=np.float32)

    index_lichsu.add_with_ids(vector_np_ls, np.array([id_lich_su]))
    lich_su[str(id_lich_su)] = tra_loi

    # L∆∞u FAISS l·ªãch s·ª≠ v√† file JSON
    faiss.write_index(index_lichsu.index, duong_dan_lich_su_faiss)
    with open(duong_dan_lich_su_json, "w", encoding="utf-8") as f:
        json.dump(lich_su, f, ensure_ascii=False, indent=2)

    print("üíæ ƒê√£ l∆∞u c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi v√†o l·ªãch s·ª≠.")
